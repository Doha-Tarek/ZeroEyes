{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1O41nPV9rcYDZucKc43bxju8gk_NiR2C5","timestamp":1719145449815}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XqaDmS70xmF0","executionInfo":{"status":"ok","timestamp":1719575844742,"user_tz":-180,"elapsed":92727,"user":{"displayName":"Salma","userId":"05084499338714599959"}},"outputId":"9a500d4e-13ad-4cc4-9713-ad24e2de6ff3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyngrok\n","  Downloading pyngrok-7.1.6-py3-none-any.whl (22 kB)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n","Installing collected packages: pyngrok\n","Successfully installed pyngrok-7.1.6\n","Collecting ultralytics\n","  Downloading ultralytics-8.2.45-py3-none-any.whl (793 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m793.6/793.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.25.2)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.0+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.0+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.0-py3-none-any.whl (25 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.3)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 ultralytics-8.2.45 ultralytics-thop-2.0.0\n"]}],"source":["!pip install pyngrok\n","!pip install ultralytics"]},{"cell_type":"code","source":["# Step 1: Install specific version\n","!pip install face_recognition==1.2.3\n","\n","# Step 2: Restart the runtime (Uncomment the following line to run it)\n","#import os\n","#os._exit(00)\n","\n","# Step 3: Verify installation (Run this in a new cell after restarting the runtime)\n","import face_recognition\n","print(face_recognition.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PopNnc9Uxp15","executionInfo":{"status":"ok","timestamp":1719575902009,"user_tz":-180,"elapsed":29356,"user":{"displayName":"Salma","userId":"05084499338714599959"}},"outputId":"677e5320-2b0c-4506-9423-19160c1f0d74"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting face_recognition==1.2.3\n","  Downloading face_recognition-1.2.3-py2.py3-none-any.whl (21 kB)\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition==1.2.3) (8.1.7)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition==1.2.3) (9.4.0)\n","Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition==1.2.3) (19.24.4)\n","Collecting face-recognition-models>=0.3.0 (from face_recognition==1.2.3)\n","  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition==1.2.3) (1.25.2)\n","Building wheels for collected packages: face-recognition-models\n","  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566170 sha256=99703c396c45c5434424b7caedf1a13d96c1d2f709a076be44a48309b8c1f03e\n","  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n","Successfully built face-recognition-models\n","Installing collected packages: face-recognition-models, face_recognition\n","Successfully installed face-recognition-models-0.3.0 face_recognition-1.2.3\n","1.2.3\n"]}]},{"cell_type":"code","source":["# app.py\n","from flask import Flask, render_template, Response\n","import cv2\n","from pyngrok import ngrok\n","from IPython.display import display, Javascript\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","import numpy as np\n","\n","app = Flask(__name__)\n","\n","def get_video_stream():\n","    js = Javascript('''\n","        async function getVideo() {\n","            const div = document.createElement('div');\n","            const video = document.createElement('video');\n","            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","            document.body.appendChild(div);\n","            div.appendChild(video);\n","            video.srcObject = stream;\n","            await video.play();\n","            const canvas = document.createElement('canvas');\n","            canvas.width = video.videoWidth;\n","            canvas.height = video.videoHeight;\n","            document.body.appendChild(canvas);\n","            const context = canvas.getContext('2d');\n","\n","            window.addEventListener('beforeunload', () => {\n","                stream.getTracks().forEach(track => track.stop());\n","            });\n","\n","            return new Promise((resolve) => {\n","                const interval = setInterval(() => {\n","                    context.drawImage(video, 0, 0, canvas.width, canvas.height);\n","                    const dataURL = canvas.toDataURL('image/jpeg', 0.8);\n","                    clearInterval(interval);\n","                    resolve(dataURL);\n","                }, 100);  // Capture every 100 milliseconds\n","            });\n","        }\n","        getVideo();\n","    ''')\n","    display(js)\n","    data = eval_js(\"getVideo()\")\n","    binary = b64decode(data.split(',')[1])\n","    np_data = np.frombuffer(binary, np.uint8)\n","    img = cv2.imdecode(np_data, cv2.IMREAD_COLOR)\n","    return img\n","\n","\n","\n"],"metadata":{"id":"oj2DJ2j4x76B","executionInfo":{"status":"ok","timestamp":1719575928025,"user_tz":-180,"elapsed":725,"user":{"displayName":"Salma","userId":"05084499338714599959"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')"],"metadata":{"id":"8uuGd2m3yCbA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719575951065,"user_tz":-180,"elapsed":20828,"user":{"displayName":"Salma","userId":"05084499338714599959"}},"outputId":"4f42e9a4-de2e-4e15-8c5d-2bfef178990e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Graduation Project /Deployment /Final_Whole_Website"],"metadata":{"id":"qFqP8GUWx6HV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719576002615,"user_tz":-180,"elapsed":764,"user":{"displayName":"Salma","userId":"05084499338714599959"}},"outputId":"63a31eab-014a-4c16-980d-4da350deeba2"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1tCxZF_4LbuiGQaCNrczmpjBOfcMC1Rgk/Graduation Project /Deployment /Final_Whole_Website\n"]}]},{"cell_type":"code","source":["from pyngrok import ngrok\n","from flask import Flask,render_template,Response, request, send_file\n","import cv2\n","from YOLO_Video import video_detection\n","from simple_facerec import SimpleFacerec\n","from ultralytics import YOLO\n","import math\n","from werkzeug.utils import secure_filename\n","from keras.models import load_model\n","from collections import deque\n","import numpy as np\n","import os\n"],"metadata":{"id":"V-MN19voNkMZ","executionInfo":{"status":"ok","timestamp":1719576017810,"user_tz":-180,"elapsed":10237,"user":{"displayName":"Salma","userId":"05084499338714599959"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from flask import Flask, render_template, Response, request, jsonify\n","import cv2\n","from pyngrok import ngrok\n","from IPython.display import display, Javascript\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","import numpy as np\n","import tensorflow as tf\n","from collections import deque\n","from werkzeug.utils import secure_filename\n","import os"],"metadata":{"id":"CYWIFZOgNmDb","executionInfo":{"status":"ok","timestamp":1719576020106,"user_tz":-180,"elapsed":321,"user":{"displayName":"Salma","userId":"05084499338714599959"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Streaming\n","def generate_frames():\n","    while True:\n","        frame = get_video_stream()\n","        ret, buffer = cv2.imencode('.jpg', frame)\n","        frame = buffer.tobytes()\n","        yield (b'--frame\\r\\n'\n","               b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n","\n","#---------------------------------------------------------------------------------------------------\n","#Fire Detection\n","CLASSES_LIST_FIRE = [\"Fire\", \"Smoke\"]\n","def detect_fire_in_frame(frame):\n","    # Your fire detection model loading code here\n","    model = YOLO(\"best (3).pt\")\n","    results = model(frame, stream=True)\n","    for r in results:\n","        boxes = r.boxes\n","        for box in boxes:\n","            x1, y1, x2, y2 = box.xyxy[0]\n","            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n","            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 255), 3)\n","            conf = np.ceil((box.conf[0].cpu() * 100)) / 100  # Move tensor to CPU\n","            cls = int(box.cls[0])\n","            class_name = CLASSES_LIST_FIRE[cls]\n","            label = f'{class_name} {conf}'\n","            t_size = cv2.getTextSize(label, 0, fontScale=1, thickness=2)[0]\n","            c2 = x1 + t_size[0], y1 - t_size[1] - 3\n","            cv2.rectangle(frame, (x1, y1), c2, [255, 0, 255], -1, cv2.LINE_AA)\n","            cv2.putText(frame, label, (x1, y1 - 2), 0, 1, [255, 255, 255], thickness=1, lineType=cv2.LINE_AA)\n","    return frame\n","\n","def generate_fire_stream():\n","    while True:\n","        frame = get_video_stream()\n","        frame = detect_fire_in_frame(frame)\n","        ret, buffer = cv2.imencode('.jpg', frame)\n","        frame = buffer.tobytes()\n","        yield (b'--frame\\r\\n'\n","               b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n","\n","\n","def detect_fire(video_path):\n","    model = YOLO(\"best (3).pt\")\n","    cap = cv2.VideoCapture(video_path)\n","    output_path = os.path.join(app.config['UPLOAD_FOLDER'], 'processed_video.mp4')\n","\n","    original_video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    original_video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","    video_writer = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'),\n","                                   cap.get(cv2.CAP_PROP_FPS), (original_video_width, original_video_height))\n","\n","    frames_queue = deque(maxlen=SEQUENCE_LENGTH)\n","    key_frame_saved = False\n","\n","    while cap.isOpened():\n","        ok, frame = cap.read()\n","        if not ok:\n","            break\n","\n","        resized_frame = cv2.resize(frame, (64, 64))\n","        normalized_frame = resized_frame / 255\n","        frames_queue.append(normalized_frame)\n","\n","        if len(frames_queue) == SEQUENCE_LENGTH:\n","            results = model(frame, stream=True)\n","            for r in results:\n","                boxes = r.boxes\n","                for box in boxes:\n","                    x1, y1, x2, y2 = box.xyxy[0]\n","                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n","                    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 255), 3)\n","                    conf = np.ceil((box.conf[0].cpu() * 100)) / 100  # Move tensor to CPU\n","                    cls = int(box.cls[0])\n","                    class_name = CLASSES_LIST_FIRE[cls]\n","                    label = f'{class_name} {conf}'\n","                    t_size = cv2.getTextSize(label, 0, fontScale=1, thickness=2)[0]\n","                    c2 = x1 + t_size[0], y1 - t_size[1] - 3\n","                    cv2.rectangle(frame, (x1, y1), c2, [255, 0, 255], -1, cv2.LINE_AA)\n","                    cv2.putText(frame, label, (x1, y1 - 2), 0, 1, [255, 255, 255], thickness=1, lineType=cv2.LINE_AA)\n","\n","            # Save this frame as a key frame if it hasn't been saved before\n","            if not key_frame_saved:\n","                key_frame_path = os.path.join(app.config['UPLOAD_FOLDER'], 'key_frame.jpg')\n","                cv2.imwrite(key_frame_path, frame)\n","                key_frame_saved = True\n","\n","        video_writer.write(frame)\n","\n","    cap.release()\n","    video_writer.release()\n","    return output_path\n","#-------------------------------------------------------------------------------------------------------------------\n","#Gun Detection\n","CLASSES_LIST_GUN = [\"Pistol\",\"Grenade\" , \"Gun\" , \"Knife\"]\n","SEQUENCE_LENGTH = 16\n","def detect_gun(video_path):\n","    model = YOLO(\"best.pt\")\n","    cap = cv2.VideoCapture(video_path)\n","    output_path = os.path.join(app.config['UPLOAD_FOLDER'], 'processed_video.mp4')\n","\n","    original_video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    original_video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","    video_writer = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'),\n","                                   cap.get(cv2.CAP_PROP_FPS), (original_video_width, original_video_height))\n","\n","    frames_queue = deque(maxlen=SEQUENCE_LENGTH)\n","    key_frame_saved = False\n","\n","    while cap.isOpened():\n","        ok, frame = cap.read()\n","        if not ok:\n","            break\n","\n","        resized_frame = cv2.resize(frame, (64, 64))\n","        normalized_frame = resized_frame / 255\n","        frames_queue.append(normalized_frame)\n","\n","        if len(frames_queue) == SEQUENCE_LENGTH:\n","            results = model(frame, stream=True)\n","            for r in results:\n","                boxes = r.boxes\n","                for box in boxes:\n","                    x1, y1, x2, y2 = box.xyxy[0]\n","                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n","                    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 255), 3)\n","                    conf = np.ceil((box.conf[0].cpu() * 100)) / 100  # Move tensor to CPU\n","                    cls = int(box.cls[0])\n","                    class_name = CLASSES_LIST_GUN[cls]\n","                    label = f'{class_name} {conf}'\n","                    t_size = cv2.getTextSize(label, 0, fontScale=1, thickness=2)[0]\n","                    c2 = x1 + t_size[0], y1 - t_size[1] - 3\n","                    cv2.rectangle(frame, (x1, y1), c2, [255, 0, 255], -1, cv2.LINE_AA)\n","                    cv2.putText(frame, label, (x1, y1 - 2), 0, 1, [255, 255, 255], thickness=1, lineType=cv2.LINE_AA)\n","\n","            # Save this frame as a key frame if it hasn't been saved before\n","            if not key_frame_saved:\n","                key_frame_path = os.path.join(app.config['UPLOAD_FOLDER'], 'key_frame.jpg')\n","                cv2.imwrite(key_frame_path, frame)\n","                key_frame_saved = True\n","\n","        video_writer.write(frame)\n","\n","    cap.release()\n","    video_writer.release()\n","    return output_path\n","\n","def detect_gun_in_frame(frame):\n","    # Placeholder function for gun detection\n","    # Implement your gun detection model here\n","    model = YOLO(\"best.pt\")\n","    results = model(frame, stream=True)\n","    for r in results:\n","        boxes = r.boxes\n","        for box in boxes:\n","            x1, y1, x2, y2 = box.xyxy[0]\n","            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n","            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 255), 3)\n","            conf = np.ceil((box.conf[0].cpu() * 100)) / 100  # Move tensor to CPU\n","            cls = int(box.cls[0])\n","            class_name = CLASSES_LIST_GUN[cls]\n","            label = f'{class_name} {conf}'\n","            t_size = cv2.getTextSize(label, 0, fontScale=1, thickness=2)[0]\n","            c2 = x1 + t_size[0], y1 - t_size[1] - 3\n","            cv2.rectangle(frame, (x1, y1), c2, [255, 0, 255], -1, cv2.LINE_AA)\n","            cv2.putText(frame, label, (x1, y1 - 2), 0, 1, [255, 255, 255], thickness=1, lineType=cv2.LINE_AA)\n","    return frame\n","\n","def generate_gun_stream():\n","    while True:\n","        frame = get_video_stream()\n","        frame = detect_gun_in_frame(frame)\n","        ret, buffer = cv2.imencode('.jpg', frame)\n","        frame = buffer.tobytes()\n","        yield (b'--frame\\r\\n'\n","               b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n","\n","\n","#----------------------------------------------------------------------------------------------------------------------\n","#Violence\n","CLASSES_LIST = [\"NonViolence\",\"Violence\"]\n","SEQUENCE_LENGTH=16\n","latest_prediction = \"No prediction yet\"  # Global variable to store the latest prediction\n","IMAGE_HEIGHT, IMAGE_WIDTH = 64, 64\n","model = tf.keras.models.load_model('best_weights.h5')\n","\n","def process_video(video_path, model_path):\n","    model = load_model(model_path)\n","    vs = cv2.VideoCapture(video_path)\n","    output_path = os.path.join(app.config['UPLOAD_FOLDER'], 'processed_video.avi')\n","\n","    original_video_width = int(vs.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    original_video_height = int(vs.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","    video_writer = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc('m', 'p', '4', 'v'),\n","                                   vs.get(cv2.CAP_PROP_FPS), (original_video_width, original_video_height))\n","\n","    frames_queue = deque(maxlen=SEQUENCE_LENGTH)\n","    predicted_class_name = ''\n","    key_frame_saved = False\n","\n","    while vs.isOpened():\n","        ok, frame = vs.read()\n","        if not ok:\n","            break\n","\n","        resized_frame = cv2.resize(frame, (64, 64))\n","        normalized_frame = resized_frame / 255\n","        frames_queue.append(normalized_frame)\n","\n","        if len(frames_queue) == SEQUENCE_LENGTH:\n","            predicted_labels_probabilities = model.predict(np.expand_dims(frames_queue, axis=0))[0]\n","            predicted_label = np.argmax(predicted_labels_probabilities)\n","            predicted_class_name = CLASSES_LIST[predicted_label]\n","            max_probability = np.max(predicted_labels_probabilities)\n","            percentage = max_probability * 100\n","\n","            # Set text color based on the prediction\n","            if predicted_class_name == \"Violence\":\n","                text_color = (0, 0, 255)  # Red color for Violence class\n","            else:\n","                text_color = (0, 255, 0)  # Green color for NonViolence class\n","\n","            text = f'{predicted_class_name}: {percentage:.2f}%'\n","            cv2.putText(frame, text, (2, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.5, text_color, 4)\n","\n","            # Save this frame as a key frame if the condition meets and it hasn't been saved before\n","            if not key_frame_saved:\n","                key_frame_path = os.path.join(app.config['UPLOAD_FOLDER'], 'key_frame.jpg')\n","                cv2.imwrite(key_frame_path, frame)\n","                key_frame_saved = True\n","\n","        video_writer.write(frame)\n","\n","    vs.release()\n","    video_writer.release()\n","    return output_path\n","\n","def preprocess_image(image_data, frame_width, frame_height):\n","    resized_frame = cv2.resize(image_data, (frame_width, frame_height))\n","    normalized_frame = resized_frame / 255.0\n","    return normalized_frame\n","\n","def generate_violence_stream():\n","    global latest_prediction\n","    frames_buffer = deque(maxlen=SEQUENCE_LENGTH)\n","    while True:\n","        frame = get_video_stream()\n","        if frame is None:\n","            print(\"Frame capture failed\")\n","            continue\n","        frame_processed = preprocess_image(frame, IMAGE_WIDTH, IMAGE_HEIGHT)\n","        if frame_processed is None:\n","            print(\"Frame preprocessing failed\")\n","            continue\n","        frames_buffer.append(frame_processed)\n","\n","        if len(frames_buffer) == SEQUENCE_LENGTH:\n","            frames = np.array(frames_buffer)\n","            frames = np.expand_dims(frames, axis=0)  # Add batch dimension\n","\n","            # Ensure the frames have the correct shape\n","            print(f\"Frames shape: {frames.shape}\")  # Debug print to check the shape\n","\n","            prediction = model.predict(frames)\n","            predicted_class = np.argmax(prediction, axis=1)[0]\n","            label = CLASSES_LIST[predicted_class]\n","            latest_prediction = label  # Update the global prediction\n","\n","            # Draw the prediction label on the frame\n","            cv2.putText(frame, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n","\n","        ret, frame_buffer = cv2.imencode('.jpg', frame)\n","        frame = frame_buffer.tobytes()\n","        yield (b'--frame\\r\\n'\n","               b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n","\n","\n"],"metadata":{"id":"d40Yw3w-OC7v","executionInfo":{"status":"ok","timestamp":1719576108303,"user_tz":-180,"elapsed":7721,"user":{"displayName":"Salma","userId":"05084499338714599959"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["!pip install flask_sqlalchemy\n","!pip install flask_login\n","!pip install bcrypt"],"metadata":{"id":"suGUmHyjNqG9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719576128157,"user_tz":-180,"elapsed":16650,"user":{"displayName":"Salma","userId":"05084499338714599959"}},"outputId":"8b075317-3363-443b-9c41-6eeeb6eadf22"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting flask_sqlalchemy\n","  Downloading flask_sqlalchemy-3.1.1-py3-none-any.whl (25 kB)\n","Requirement already satisfied: flask>=2.2.5 in /usr/local/lib/python3.10/dist-packages (from flask_sqlalchemy) (2.2.5)\n","Requirement already satisfied: sqlalchemy>=2.0.16 in /usr/local/lib/python3.10/dist-packages (from flask_sqlalchemy) (2.0.31)\n","Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask>=2.2.5->flask_sqlalchemy) (3.0.3)\n","Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask>=2.2.5->flask_sqlalchemy) (3.1.4)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask>=2.2.5->flask_sqlalchemy) (2.2.0)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask>=2.2.5->flask_sqlalchemy) (8.1.7)\n","Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=2.0.16->flask_sqlalchemy) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=2.0.16->flask_sqlalchemy) (3.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask>=2.2.5->flask_sqlalchemy) (2.1.5)\n","Installing collected packages: flask_sqlalchemy\n","Successfully installed flask_sqlalchemy-3.1.1\n","Collecting flask_login\n","  Downloading Flask_Login-0.6.3-py3-none-any.whl (17 kB)\n","Requirement already satisfied: Flask>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from flask_login) (2.2.5)\n","Requirement already satisfied: Werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from flask_login) (3.0.3)\n","Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.0.4->flask_login) (3.1.4)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.0.4->flask_login) (2.2.0)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.0.4->flask_login) (8.1.7)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from Werkzeug>=1.0.1->flask_login) (2.1.5)\n","Installing collected packages: flask_login\n","Successfully installed flask_login-0.6.3\n","Collecting bcrypt\n","  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: bcrypt\n","Successfully installed bcrypt-4.1.3\n"]}]},{"cell_type":"code","source":["from flask import Flask, render_template, redirect, request,session, Response,url_for\n","from flask_sqlalchemy import SQLAlchemy\n","from flask_login import LoginManager, login_user, login_required\n","from sqlalchemy.exc import IntegrityError\n","from bcrypt import hashpw, gensalt,checkpw"],"metadata":{"id":"8N8RjKL-r5iS","executionInfo":{"status":"ok","timestamp":1719576136469,"user_tz":-180,"elapsed":770,"user":{"displayName":"Salma","userId":"05084499338714599959"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["\n","app=Flask(__name__)\n","app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///../database/users.db'\n","app.config['SQLALCHEMY_TRACK_MODIFICATIONS']  = False\n","app.config['SECRET_KEY']='a92cf3597ef6066d2aacb1c37b6bbf4dd879e9e08f578fe9b4c619b3224d9ed7'\n","\n","camera=cv2.VideoCapture(1)\n","app.config['UPLOAD_FOLDER'] = 'static/videos'\n","\n","\n","\n","db = SQLAlchemy(app)\n","app.app_context().push()\n","\n","class User(db.Model):\n","    id = db.Column(db.Integer, primary_key=True)\n","    username = db.Column(db.String(20), unique=True, nullable=False)\n","    email = db.Column(db.String(100), unique=True, nullable=False)\n","    password = db.Column(db.String(120), nullable=False)\n","\n","    def __init__(self,username,email,password):\n","        self.username = username\n","        self.email = email\n","        self.password = password\n","\n","login_manager = LoginManager()\n","login_manager.init_app(app)\n","\n","\n","@login_manager.user_loader\n","def load_user(user_id):\n","    return User.query.get(int(user_id))\n","\n","@app.route(\"/\")\n","def home():\n","    return render_template(\"index.html\")\n","\n","@app.route(\"/login\", methods=['GET','POST'])\n","def login():\n","    if request.method == \"POST\":\n","        username = request.form['username']\n","        password = request.form['password']\n","\n","        user = User.query.filter_by(username=username).first()\n","\n","        if user:\n","            if checkpw(password.encode('utf-8'), user.password):\n","                session['username'] = user.username\n","                session['password'] = user.password\n","                # return render_template(\"fire.html\")\n","                return redirect('/fire')\n","\n","            else:\n","                error = \"Invalid password\"\n","                return render_template(\"Login.html\", error=error)\n","        else:\n","            error = \"Invalid username\"\n","            return render_template(\"Login.html\", error=error)\n","\n","    return render_template(\"Login.html\")\n","\n","@app.route(\"/register\", methods=['GET','POST'])\n","def register():\n","    if request.method == \"POST\":\n","        username = request.form['username']\n","        email = request.form['email']\n","        password = request.form['password']\n","        confirm_password = request.form['confirm_password']\n","\n","        # Check if passwords match\n","        if password != confirm_password:\n","            error = \"Passwords do not match\"\n","            return render_template(\"Register.html\", error=error)\n","\n","        # Hash the password before storing\n","        hashed_password = hashpw(password.encode('utf-8'),gensalt() )\n","        try:\n","            new_user = User(username=username,email=email,password=hashed_password)\n","            db.session.add(new_user)\n","            db.session.commit()\n","            return redirect(\"/login\")\n","\n","        except IntegrityError as e:\n","            db.session.rollback()  # Rollback the transaction\n","            error = None\n","            if 'UNIQUE constraint failed: user.username' in str(e):\n","                error = \"Username already exists\"\n","            elif 'UNIQUE constraint failed: user.email' in str(e):\n","                error = \"Email already exists\"\n","            else:\n","                error = \"An error occurred, please try again.\"\n","            return render_template(\"Register.html\", error=error)\n","    else:\n","        return render_template(\"Register.html\")"],"metadata":{"id":"JZRo-Rbl3lp7","executionInfo":{"status":"ok","timestamp":1719576138579,"user_tz":-180,"elapsed":318,"user":{"displayName":"Salma","userId":"05084499338714599959"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["#-----------------------------------------------------------------------------------\n","# Fire Page\n","@app.route('/fire')\n","def fire():\n","    if 'username' in session:\n","        return render_template(\"fire.html\",username=session)\n","    else:\n","        return redirect('/login')\n","\n","ALLOWED_EXTENSIONS = ['mp4']\n","\n","def allowed_file(filename):\n","    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n","\n","@app.route('/upload', methods=['GET', 'POST'])\n","def upload():\n","    if request.method == 'POST':\n","        if 'video' not in request.files:\n","            return 'No video file found'\n","\n","        f = request.files['video']\n","\n","        if f.filename == '':\n","            return 'No video file selected'\n","\n","        filename = secure_filename(f.filename)\n","        upload_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n","        f.save(upload_path)\n","        processed_video_path = detect_fire(upload_path)\n","\n","        key_frame_path = os.path.join(app.config['UPLOAD_FOLDER'], 'key_frame.jpg')\n","        return render_template('Results_Fire.html', video_file=os.path.basename(processed_video_path), key_frame=os.path.basename(key_frame_path))\n","    return render_template('fire.html')\n","\n","@app.route('/download/<filename>')\n","def download(filename):\n","    return send_file(os.path.join(app.config['UPLOAD_FOLDER'], filename), as_attachment=True)\n","\n","@app.route('/video_fire_stream')\n","def video_fire_stream():\n","    return Response(generate_fire_stream(), mimetype='multipart/x-mixed-replace; boundary=frame')\n","\n","\n","#--------------------------------------------------------------------------------------------------\n","# Gun Page\n","@app.route('/gun')\n","def gun():\n","    return render_template('gun.html')\n","\n","@app.route('/upload_gun', methods=['GET', 'POST'])\n","def upload_gun():\n","    if request.method == 'POST':\n","        if 'video' not in request.files:\n","            return 'No video file found'\n","\n","        f = request.files['video']\n","\n","        if f.filename == '':\n","            return 'No video file selected'\n","\n","        filename = secure_filename(f.filename)\n","        upload_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n","        f.save(upload_path)\n","        processed_video_path = detect_gun(upload_path)\n","\n","        key_frame_path = os.path.join(app.config['UPLOAD_FOLDER'], 'key_frame.jpg')\n","        return render_template('Results_gun.html', video_file=os.path.basename(processed_video_path), key_frame=os.path.basename(key_frame_path))\n","    return render_template('gun.html')\n","\n","@app.route('/download/<filename>')\n","def download_gun(filename):\n","    return send_file(os.path.join(app.config['UPLOAD_FOLDER'], filename), as_attachment=True)\n","\n","@app.route('/video_gun_stream')\n","def video_gun_stream():\n","    return Response(generate_gun_stream(), mimetype='multipart/x-mixed-replace; boundary=frame')\n","\n","\n","#---------------------------------------------------------------------------------------------------------------------\n","# Recognition Page\n","app.config['UPLOAD_FOLDER'] = 'static/videos'\n","ALLOWED_EXTENSIONS = ['mp4']\n","\n","# Load face recognition model and encodings\n","sfr = SimpleFacerec()\n","sfr.load_encoding_images(\"images/\")  # Update the path accordingly\n","def detect_known_faces_in_frame(frame):\n","    face_locations, face_names = sfr.detect_known_faces(frame)\n","    for (top, right, bottom, left), name in zip(face_locations, face_names):\n","        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n","        cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_DUPLEX, 0.5, (0, 0, 255), 1)\n","    return frame\n","\n","def generate_recog_stream():\n","    while True:\n","        frame = get_video_stream()\n","        frame = detect_known_faces_in_frame(frame)\n","        ret, buffer = cv2.imencode('.jpg', frame)\n","        frame = buffer.tobytes()\n","        yield (b'--frame\\r\\n'\n","               b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n","\n","\n","\n","@app.route('/recog')\n","def recog():\n","    return render_template('recog.html')\n","\n","\n","def detect_faces(video_path):\n","    cap = cv2.VideoCapture(video_path)\n","    frame_width = int(cap.get(3))\n","    frame_height = int(cap.get(4))\n","    out = cv2.VideoWriter(os.path.join(app.config['UPLOAD_FOLDER'], 'output.mp4'),\n","                          cv2.VideoWriter_fourcc(*'mp4v'), 10, (frame_width, frame_height))\n","    key_frame_path = os.path.join(app.config['UPLOAD_FOLDER'], 'key_frame.jpg')\n","    key_frame_saved = False\n","\n","    while True:\n","        success, img = cap.read()\n","        if not success:\n","            break\n","\n","        face_locations, face_names = sfr.detect_known_faces(img)\n","        for face_loc, name in zip(face_locations, face_names):\n","            y1, x2, y2, x1 = face_loc[0], face_loc[1], face_loc[2], face_loc[3]\n","            cv2.putText(img, name, (x1, y1 - 10), cv2.FONT_HERSHEY_DUPLEX, 1, (0, 0, 200), 2)\n","            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 200), 4)\n","\n","        if face_names and not key_frame_saved:\n","            cv2.imwrite(key_frame_path, img)\n","            key_frame_saved = True\n","\n","        out.write(img)\n","\n","    cap.release()\n","    out.release()\n","    cv2.destroyAllWindows()\n","\n","    if not key_frame_saved:\n","        cap = cv2.VideoCapture(video_path)\n","        success, img = cap.read()\n","        if success:\n","            cv2.imwrite(key_frame_path, img)\n","        cap.release()\n","\n","    return key_frame_path\n","\n","\n","@app.route('/upload_Recog', methods=['GET', 'POST'])\n","def upload_Recog():\n","    if 'video' not in request.files:\n","        return 'No video file found'\n","\n","    video = request.files['video']\n","    if video.filename == '':\n","        return 'No video file selected'\n","\n","    if video and allowed_file(video.filename):\n","        video_path = os.path.join(app.config['UPLOAD_FOLDER'], video.filename)\n","        video.save(video_path)\n","\n","        key_frame_path = detect_faces(video_path)\n","        return render_template('Results_Recog.html', video_name='output.mp4', key_frame=os.path.basename(key_frame_path))\n","\n","    return 'Invalid file type'\n","\n","\n","@app.route('/download/<filename>')\n","def download_Recog(filename):\n","    detected_video_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n","    return send_file(detected_video_path, as_attachment=True)\n","\n","@app.route('/video_recog_stream')\n","def video_recog_stream():\n","    return Response(generate_recog_stream(), mimetype='multipart/x-mixed-replace; boundary=frame')\n","\n","\n","#----------------------------------------------------------------------------------------------------------------------\n","# Violence Page\n","app.config['UPLOAD_FOLDER'] = 'static/videos'\n","@app.route('/violence')\n","def violence():\n","    return render_template('violence.html')\n","@app.route('/uploader', methods=['GET', 'POST'])\n","def uploader():\n","    if request.method == 'POST':\n","        f = request.files['file']\n","        filename = secure_filename(f.filename)\n","        upload_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n","        f.save(upload_path)\n","        processed_video_path = process_video(upload_path, 'best_weights.h5')\n","\n","        # Corrected line: Use 'UPLOAD_FOLDER' instead of 'UPLOAD_API'\n","        key_frame_path = os.path.join(app.config['UPLOAD_FOLDER'], 'key_frame.jpg')\n","        return render_template('Results_Violence.html', video_file=os.path.basename(processed_video_path), key_frame=os.path.basename(key_frame_path))\n","\n","@app.route('/video_violence_stream')\n","def video_violence_stream():\n","    return Response(generate_violence_stream(), mimetype='multipart/x-mixed-replace; boundary=frame')\n","\n","@app.route('/violence_prediction', methods=['GET'])\n","def violence_prediction():\n","    global latest_prediction\n","    return jsonify({\"prediction\": latest_prediction})\n","\n","\n","@app.route('/download/<filename>')\n","def download_file(filename):\n","    return send_file(os.path.join(app.config['UPLOAD_FOLDER'], filename), as_attachment=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9D6sFEvr4F1Q","executionInfo":{"status":"ok","timestamp":1719576145439,"user_tz":-180,"elapsed":5439,"user":{"displayName":"Salma","userId":"05084499338714599959"}},"outputId":"ca372844-da6c-4e0b-b5b2-0cc9c8509a60"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["3 encoding images found.\n","Encoding images loaded\n"]}]},{"cell_type":"code","source":["\n","if __name__ == \"__main__\":\n","   ngrok.set_auth_token(\"2iBxvSm3FTTtG79Qs9qVVBOBQgP_3nMCR13xT6uf9jZraW7sQ\")\n","   ngrok_tunnel = ngrok.connect(5000)\n","   print('Public URL:', ngrok_tunnel.public_url)\n","   app.run()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g2rBNAPe39Rh","outputId":"79d1fb14-b143-4234-d87d-ecd11fcfd75f","executionInfo":{"status":"ok","timestamp":1719579893790,"user_tz":-180,"elapsed":42817,"user":{"displayName":"Salma","userId":"05084499338714599959"}}},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Public URL: https://9462-34-125-12-103.ngrok-free.app\n"," * Serving Flask app '__main__'\n"," * Debug mode: off\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n"," * Running on http://127.0.0.1:5000\n","INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:18] \"GET / HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:18] \"GET /static/Lib/animate/animate.min.css HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:18] \"GET /static/Lib/owlcarousel/assets/owl.carousel.min.css HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:18] \"GET /static/img/face.png HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:18] \"GET /static/css/style.css HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:18] \"GET /static/img/icon/face-icon.png HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:18] \"GET /static/css/bootstrap.min.css HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:18] \"GET /static/img/camera.jpg HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:18] \"GET /static/img/icon/fire-icon.png HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:18] \"GET /static/Lib/waypoints/waypoints.min.js HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:18] \"GET /static/Lib/owlcarousel/owl.carousel.min.js HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:18] \"GET /static/Lib/counterup/counterup.min.js HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:18] \"GET /static/img/violence.png HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:18] \"GET /static/Lib/lightbox/css/lightbox.min.css HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:18] \"GET /static/js/main.js HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:18] \"GET /static/Lib/isotope/isotope.pkgd.min.js HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:18] \"GET /static/img/fire.jpg HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:18] \"GET /static/img/gun.png HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:18] \"GET /static/img/icon/violence-icon.png HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:18] \"GET /static/img/contact_us_banner1.jpg HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:18] \"GET /static/Lib/easing/easing.min.js HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:18] \"GET /static/Lib/wow/wow.min.js HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:18] \"GET /static/img/icon/gun-icon.png HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:20] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:21] \"GET /login HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:21] \"GET /static/css/main.css HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:30] \"\u001b[32mPOST /login HTTP/1.1\u001b[0m\" 302 -\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:31] \"GET /fire HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [28/Jun/2024 13:04:32] \"GET /static/images/Fire.png HTTP/1.1\" 200 -\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"q1oZrf4n8OYQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"npXAtzrQ8j3j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"so70sLtD_qCa"},"execution_count":null,"outputs":[]}]}